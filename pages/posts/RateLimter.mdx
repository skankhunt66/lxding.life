import post from '../../templates/post'
import app from '../../templates/post'

export const meta = {
  title: '从Leaky Bucket说起',
  author: 'yutsun',
  date: '2020-04-15',
  description: 'summary'
}

export default post(meta)

<!-- content starts here -->

#### 问题背景

目前在开发一个设备管理系统，其中一个核心模块的作用是以一定的频率采集设备的性能/状态数据，再分析，产生告警。
分析过程并不复杂，大部分是数值和字符串对比，同时有一些查库操作。

系统性能设计标准为单机1W节点，这种监控系统一般部署在内网，QPS很低，所以压力主要集中在数据收集和处理上。

使用vm工具监测系统进程观察到进程cpu占用率偶有飙升现象，频率跟数据采集频率一致，dump线程快照分析确认是数据分析
占用了大部分cpu时间，为了提高系统稳定性，尝试对做限流处理。

我们知道，分布式系统的高可用离不开限流、降级、熔断这三种手段。
限流的目的是降低大量请求对服务的压力，使服务在合理的负载下运行，保持可用性。

常见的限流算法有计数器、漏桶和令牌三种，下面逐个介绍一下。

#### 计数器

计数器算法是把时间分割成区间，在区间的头部初始化单位时间内请求的数量的上限，超出上限的请求执行限流策略。
这个方法比较直观，但假如请求集中在区间头或者区间尾，这个方法可能就不那么有效。当然这个问题可以通过细化时间
区间粒度的方式来解决。

##### 漏桶（Leaky Bucket）

漏桶算法假设有一个固定容量的请求桶，所有请求先进入桶中，超出桶容量的请求会被丢弃，同时桶以固定的速率
释放请求--即漏水。
以上是漏洞算法的一种常见描述，其中的桶实质上是一个队列，请求会以平稳的速度被接受，不会有波动。

漏桶算法的另一个描述是，当请求到来时，我们先去查看桶是否是满的，如果未满，请求就被接受，并往桶中加水，
桶里的水依然以固定速率漏出。

wiki上称第一种“as a queue”--作为队列，第二种“as a meter”--作为水表计价器，很形象。

##### 令牌桶（Token Bucket）

令牌桶算法假设有一个令牌桶，我们以一个频率生成令牌，将令牌放入桶中，请求先要从桶中取出令牌才能被响应，若
令牌桶为空，则执行限流策略。

不难看出，令牌桶和计价器漏桶实质上是等同的。

##### 限流策略

限流策略主要分两种，请求丢弃或者等待。

google的guava里的RateLimter正是令牌桶的一个实现。事实上，guava提供了两种实现，SmoothBursty和SmoothWarmingUp，相当贴心。

简单来讲，bursty如其名，提供了一定程度弹性，会把闲置的令牌攒起来应对突发请求（其实也只留了一秒的令牌量，并不多）。

而warming up就更巧妙也更贴近现实一点，系统在闲置一段时间后，由于热点缓存失效或者buffer清空，在新一轮请求到来后，有一段时间的处理能力
比正常状态下低或者高。warming up可以做到调整在这段时间内令牌的产生速度。

#### RateLimter使用例子

RateLimter的使用非常简单，这是一个bursty的例子：

        // 每秒100个令牌
        RateLimiter rateLimiter = RateLimiter.create(100);
        rateLimiter.acquire(1);
        // do something

这是一个warming up的例子：

        //每秒1000个令牌，闲置状态下，1000秒后恢复正常速率
        RateLimiter rateLimiter = RateLimiter.create(100, 1000, TimeUnit.SECONDS);
        rateLimiter.acquire(1);
        // do something

#### RateLimter设计思想

RateLimter在设计中有两点是值得特别提到的，一是等待代偿，二是热身模型。

##### 等待代偿

假设请求需要10个令牌才可以执行，在令牌桶初始化的时刻，第一次请求到来，正常情况下请求需要等待令牌桶产生10枚令牌，但这显然不合理，RateLimiter的做法
是放行这次请求，10枚令牌的时间成本由下一次请求承担。

第n次请求所需要等待的时间是令牌桶产生第n-1次请求消耗所需的时间，这个就是等待代偿。

#### 热身

热身的基本思路上文已经讲了，现在来看看设计者是怎么讲的。

> 要知道，这样的RateLimiter对过去的记忆非常肤浅：它只记得上次的请求。如果RateLimiter长期未被使用，然后有一个请求到达并立即通过了怎么办？
> 这个RateLimiter会立即忘记过去的利用率不足。这可能会导致利用率不足或溢出，这取决于没有使用预期的速率的实际后果。
> 过去的利用率不足可能意味着资源过剩。那么，RateLimiter应该加快一段时间的速度，利用这些资源的优势。当速率应用于网络（限制带宽）时，这一点很重要，
> 过去的利用率不足通常会产生 "几乎是空的缓冲区"，可以立即填充。
> 另一方面，过去的利用率不足可能意味着 "负责处理请求的服务器对未来的请求准备不足"，也就是说，它的缓存可能会失效，请求变得更容易触发查库等代价比较高的操作
>（这个例子的一个更极端的情况是，当服务器刚刚启动，而它主要是忙于让自己的速度提升）。为了处理这种情况，我们增加了一个额外的维度，即 "过去的利用率不足"，
> 由 "storagePermits "变量建模。这个变量在没有使用不足的情况下是零，如果使用不足的情况足够大，它可以增长到maxSredPermits。因此，通过调用accept(points)，所请求的许可证将来自以下几个路径。
> stored permits和fresh permits

上面是SmoothWarmingUp类里的部分注释，后面有一个详细举例，感兴趣的可以去看看。

有意思的地方是SmoothWarmingUp把冷却期的令牌最慢产生速率写死了，数值为正常速率的1/3。

注释里作者提到可以采用可积分函数表示冷却期令牌产生的速度变化曲线，其积分表示产生对应令牌数量的时间，实际实现上就是一个简单的线性函数。

令牌桶算法比较典型的应用在tcp/ip的流量控制里，因为系统可接受的流量显然受制于带宽和缓存，资源是比较容易推算的。
在我们的应用场景里，通过控制流量去人为的调整数据处理速率，降低cpu占用率，我个人不认为是一个有效的手段，只是抱着学习的想法了解了一下令牌桶。
我想问题的根源可能在于分析数据的线程池设计不合理，导致线程频繁切换。

由此引申出来的思考是线程池究竟要如何设置才是合理的，可否根据io时间和cpu计算时间的比例再加上cpu实际线程数来推算出来？
另外还有一个问题，当系统中有多个进程时，如何分配cpu资源才更合理？或者cpu资源无法分配，只能通过系统抢占调度？好吧，这听起来也很合理，待我再研究一下。

令牌桶和信号量看起来也有那么一点像，区别是令牌桶根据可用资源限制请求处理速率，信号量主要是限制并发量。
有一个有趣的定理叫做Little's Law，可以根据处理速率和队列大小算出合理的系统吞吐量。
